{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Required on some Windows machines\n",
    "import os\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH \"] = \"true\"\n",
    "\n",
    "import h5py\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from deepalign import Dataset\n",
    "from deepalign import fs\n",
    "from deepalign.alignments import ALIGNERS\n",
    "from deepalign.alignments.confnet import ConfNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To speed up the evaluation, we are caching all results. You will have received these cache files with the download of the GitHub release. In case you want to run your own experiments, this is the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def get_aligner(model_file, dataset):\n",
    "    if 'confnet' in model_file.ad:\n",
    "        aligner = ALIGNERS[model_file.ad[:-2]](dataset,\n",
    "                                               use_case_attributes=model_file.use_case_attributes,\n",
    "                                               use_event_attributes=model_file.use_event_attributes,\n",
    "                                               align_steps=10)\n",
    "        aligner.load(str(fs.MODEL_DIR / model_file.name), dataset)\n",
    "    else:\n",
    "        aligner = ALIGNERS[model_file.ad]()\n",
    "        aligner.load(str(fs.MODEL_DIR / model_file.name))\n",
    "    \n",
    "    return aligner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aaa29b56158a4c89ac177ad5986212dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "text": [
      "Step 1 → 0.9140007495880127s (25000, 27) finished=3618\n",
      "Step 2 ← 0.677009105682373s (25000, 27) finished=3618\n",
      "Step 3 → 0.6100156307220459s (25000, 27) finished=3769\n",
      "Step 4 ← 0.5740082263946533s (25000, 27) finished=4277\n",
      "Step 5 → 0.3769993782043457s (25000, 27) finished=4782\n",
      "Step 6 ← 0.1271042823791504s (25000, 27) finished=4805\n",
      "Step 7 → 0.11500000953674316s (25000, 27) finished=4832\n",
      "Step 8 ← 0.11099529266357422s (25000, 27) finished=4833\n",
      "Step 9 → 0.10400032997131348s (25000, 27) finished=4833\n",
      "Step 10 ← 0.11799955368041992s (25000, 27) finished=5000\n",
      "Step 1 → 2.067323923110962s (25000, 27) finished=3797\n",
      "Step 2 ← 1.2885076999664307s (25000, 27) finished=3797\n",
      "Step 3 → 0.994004487991333s (25000, 27) finished=3901\n",
      "Step 4 ← 0.9129984378814697s (25000, 27) finished=4388\n",
      "Step 5 → 0.5460047721862793s (25000, 27) finished=4781\n",
      "Step 6 ← 0.1810016632080078s (25000, 27) finished=4820\n",
      "Step 7 → 0.2239995002746582s (25000, 27) finished=4831\n",
      "Step 8 ← 0.1741173267364502s (25000, 27) finished=4841\n",
      "Step 9 → 0.21913409233093262s (25000, 27) finished=4848\n",
      "Step 10 ← 0.21351003646850586s (25000, 27) finished=4853\n",
      "Step 1 → 1.888357162475586s (25000, 27) finished=3619\n",
      "Step 2 ← 2.3807384967803955s (25000, 27) finished=3619\n",
      "Step 3 → 1.636017084121704s (25000, 27) finished=3851\n",
      "Step 4 ← 1.721189260482788s (25000, 27) finished=4313\n",
      "Step 5 → 1.3127295970916748s (25000, 27) finished=4786\n",
      "Step 6 ← 0.22400116920471191s (25000, 27) finished=4825\n",
      "Step 7 → 0.20199894905090332s (25000, 27) finished=4840\n",
      "Step 8 ← 0.2047421932220459s (25000, 27) finished=4843\n",
      "Step 9 → 0.18173742294311523s (25000, 27) finished=4843\n",
      "Step 10 ← 0.1965479850769043s (25000, 27) finished=4992\n",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "Y:\\Repos_Uni\\deepalign\\deepalign\\processmining\\log.py:58: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(self.cases)[indices]\n",
      "100%|██████████| 610/610 [00:11<00:00, 53.97it/s]\n",
      "100%|██████████| 610/610 [00:11<00:00, 51.85it/s]\n",
      "p2p-0.3-1: 100%|██████████| 610/610 [00:11<00:00, 52.20it/s]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "synthetic = ['paper', 'p2p', 'small', 'medium', 'huge', 'wide']\n",
    "\n",
    "models = sorted(list(set([f.name.replace('_forward', '').replace('_backward', '')\n",
    "                          for f in fs.get_aligner_files()])))\n",
    "\n",
    "models = [m for m in models if not (fs.RESULT_DIR / (fs.ModelFile(m).name + '.h5')).exists()]\n",
    "\n",
    "for model in tqdm(models):\n",
    "    model_file = fs.AlignerFile(model)\n",
    "    dataset = Dataset(model_file.event_log_name,\n",
    "                      use_case_attributes=model_file.use_case_attributes,\n",
    "                      use_event_attributes=model_file.use_event_attributes)\n",
    "    aligner = get_aligner(model_file, dataset)\n",
    "\n",
    "    if isinstance(aligner, ConfNet):\n",
    "        alignments, beams, costs = aligner.batch_align(dataset, batch_size=5000)\n",
    "    else:\n",
    "        try:\n",
    "            alignments, beams, costs = aligner.align(dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "    with h5py.File(str(fs.RESULT_DIR / (model_file.name + '.h5')), 'w') as file:\n",
    "        file.create_dataset('alignments', data=alignments, compression=\"gzip\", compression_opts=9)\n",
    "        file.create_dataset('beams', data=beams, compression=\"gzip\", compression_opts=9)\n",
    "        file.create_dataset('costs', data=costs, compression=\"gzip\", compression_opts=9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}